{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code block 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import re\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "grav_acc = 9.81\n",
    "import logging\n",
    "from typing import Tuple, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake GUI for User Inputs (modify segmentation, annotation, and design parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'confidential'        \n",
    "dry_fire = False\n",
    "\n",
    "# display settings\n",
    "plot_line_width = 1.0\n",
    "plot_primary_line_alpha = 1.0\n",
    "plot_secondary_line_alpha = 0.5\n",
    "plot_grid_line_alpha = 0.5\n",
    "plot_title_font_size = 18\n",
    "\n",
    "full_force_range = range(1, 6)\n",
    "full_IMU_range = ['X', 'Y', 'Z']\n",
    "IMUs_to_plot = ['X', 'Y', 'Z']\n",
    "\n",
    "# Modify these parameters to change the time range plotted\n",
    "plot_start_time = None\n",
    "plot_end_time = None\n",
    "plot_start_time = time(00, 00, 9)   # time(hour, min, sec)\n",
    "plot_end_time = time(00, 1, 44)     # time(hour, min, sec)\n",
    "\n",
    "# Modify these parameters with caution as they drastically affect the performance of the segmentation code\n",
    "rolling_window_width = 21           # design choice: size of moving average window\n",
    "event_derivative_threshold_ADC = 4  # design choice: derivative threshold\n",
    "horizon = 5                         # design choice: horizon\n",
    "\n",
    "# Modify these parameters according to use case\n",
    "n_seconds_x_tick = 5                # the number of seconds between each x-tick in the plot \n",
    "forces_to_plot = range(1, 6)        # the forces to plot (e.g., [1, 2, 3] or range(1, 4) plots forces F1, F2, and F3)\n",
    "magnitude_threshold_ADC = 275       # threshold for eliminating minor peaks to speed up the segmentation and annotation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "calibration_dict = {}\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv') and (file.startswith('R_U_') or file.startswith('U_') or file.startswith('Trials')):\n",
    "\n",
    "            # Defining trial names and loading pd data frames from saved .csv files\n",
    "            file_path = os.path.join(root, file)\n",
    "            parts = file_path.split(os.path.sep)\n",
    "            c_num = parts[-3].split('_')[1]\n",
    "            u_num = parts[-2].split('_')[1]\n",
    "            task = parts[-1].split('_')[0].strip('.csv')\n",
    "            key = f'C{c_num}_U{u_num}_{task}'\n",
    "            df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "            # Checking for corrupted data and excluding them from analyzed data\n",
    "            target_num_columns = 8 if file.startswith('R_U_') else 15 if file.startswith('U_') else 33\n",
    "            empty_rows = df.loc[df.isnull().any(axis=1)].index.tolist()\n",
    "            row_lengths = df.apply(len, axis=1)\n",
    "            long_rows = row_lengths[row_lengths > target_num_columns].index.tolist()\n",
    "            \n",
    "            if empty_rows != []:\n",
    "                logger.warning(f\"Empty rows at indices {empty_rows} for {key} ({len(empty_rows)} rows)\")\n",
    "            if long_rows != []:\n",
    "                logger.warning(f\"Long rows at indices {long_rows} for {key} ({len(long_rows)} rows). \\nThis occurs when previus rows were interrupted before completion.\")\n",
    "            \n",
    "            if file.startswith('R_U_') or file.startswith('U_'):\n",
    "                data_dict[key] = df.drop(long_rows + empty_rows) \n",
    "            elif file.startswith('Trials'):\n",
    "                calibration_dict[key] = df.drop(long_rows + empty_rows) \n",
    "            \n",
    "print(data_dict.keys())\n",
    "print(calibration_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_components(key: str) -> Tuple[Union[int, float], Union[int, float]]:\n",
    "    \"\"\"\n",
    "    Extracts company and user IDs from a trial key string.\n",
    "    Args:\n",
    "        key (str): The trial key string, e.g., 'C123_U456_R' or 'C789_U012_U'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of (company_id, user_id), where both are integers if the\n",
    "            key is valid, or (float('inf'), float('inf')) if the key is invalid.\n",
    "    \"\"\"\n",
    "    match = re.match(r'C(\\d+)_U(\\d+)_(R|U)', key)\n",
    "    if match:\n",
    "        company_id, user_id, = map(int, match.groups()[:2])\n",
    "        return (company_id, user_id)\n",
    "    return float('inf'), float('inf')\n",
    "\n",
    "def get_trial_name(key: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Splits a trial name into base name (company and user IDs) and task components.\n",
    "\n",
    "    Args:\n",
    "        key (str): The trial key string, e.g., 'C123_U456_R' or 'C789_U012_U'.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, str]: A tuple of (base_name, task), where base_name is 'company_user' and task is the remaining component.\n",
    "    \"\"\"\n",
    "    parts = key.split('_')\n",
    "    company = parts[0]\n",
    "    user = parts[1]\n",
    "    task = parts[2]\n",
    "    \n",
    "    base_name = f'{company}_{user}'\n",
    "    return base_name, task\n",
    "\n",
    "def plot_trial(trial_name:str, df:pd.DataFrame, dry_fire=False, start=None, end=None) -> list[int] | None:\n",
    "    \"\"\"\n",
    "    Plots force, gyro, and accelerometer data for a trial with customizable time range.\n",
    "\n",
    "    Args:\n",
    "        trial_name (str): Name of the trial, used for titles and saving the plot.\n",
    "        df (pd.DataFrame): DataFrame containing trial data with 'Timestamp', force, gyro, and accelerometer columns.\n",
    "        dry_fire (boolean): Boolean indicating dry fire or live_fire.\n",
    "        start (datetime.time, optional): Start time for the x-axis. Defaults to None. This affects what is displayed, but not the actual segmentation.\n",
    "        end (datetime.time, optional): End time for the x-axis. Defaults to None. This affects what is displayed, but not the actual segmentation.\n",
    "\n",
    "    Returns:\n",
    "        list[int] | None: List of peak indices for segmented force data if only one force is plotted (when annotating segmented spikes), otherwise None.\n",
    "    \"\"\"\n",
    "    global grav_acc\n",
    "\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'orange']\n",
    "\n",
    "    figsize = (30, 12) if dry_fire else (30, 30)\n",
    "    n_subplots = 2 if dry_fire else 4\n",
    "    fig, axes = plt.subplots(n_subplots, 1, figsize=figsize)\n",
    "    ax1, ax2, ax3, ax4 = (axes[0], axes[1], None, None) if dry_fire else axes\n",
    "\n",
    "    force_ADC_columns = [f'F{force_to_plot}_ADC' for force_to_plot in forces_to_plot]\n",
    "    gyro_columns = [f'Gyro_{IMU_to_plot}' for IMU_to_plot in IMUs_to_plot]\n",
    "    acc_columns = [f'Acc_{IMU_to_plot}' for IMU_to_plot in IMUs_to_plot]\n",
    "\n",
    "    lines_ax1 = []\n",
    "    lines_ax2 = []\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.xaxis.set_ticks([]) \n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "        ax.xaxis.set_major_locator(mdates.SecondLocator(interval=n_seconds_x_tick))\n",
    "        # Setting limits using provided start and end times\n",
    "        if start is not None and end is not None:\n",
    "            reference_date = df['Timestamp'].iloc[0].date()\n",
    "            start_time = datetime.combine(reference_date, start).replace(microsecond=000000, tzinfo=pytz.UTC)\n",
    "            end_time = datetime.combine(reference_date, end).replace(microsecond=000000, tzinfo=pytz.UTC)\n",
    "            ax.set_xlim(start_time, end_time)\n",
    "\n",
    "        if ax in [ax1, ax2]:\n",
    "            ax.grid(which='minor', alpha=plot_grid_line_alpha, zorder=0)\n",
    "            ax.set_ylabel('Raw Data Derivative (ADC/s)')\n",
    "            ax.yaxis.set_major_locator(MultipleLocator(50))\n",
    "            ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "            ax.grid(which='major', axis='y', linestyle='-', color='k', alpha=plot_grid_line_alpha, zorder=0)\n",
    "            ax.yaxis.set_tick_params(which='major', labelright=True)\n",
    "            ax.set_ylim(220, 470)\n",
    "    \n",
    "    # Plots segmented spikes in subplot 1\n",
    "    for idx, force_ADC_column in enumerate(force_ADC_columns):\n",
    "\n",
    "        segmented_force = df[force_ADC_column].where(df['Spike_counter'].notna())\n",
    "\n",
    "        line, = ax1.plot(df['Timestamp'], segmented_force, label=force_ADC_column, color=colors[idx], linewidth=plot_line_width, zorder=10)\n",
    "        lines_ax1.append(line)\n",
    "        ax1.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "        ax1.set_title(f'Segmented Forces for {trial_name}', fontsize=plot_title_font_size)\n",
    "\n",
    "        # When annottaing, spike counters are shown in the plot to help annotator remove undesired segments\n",
    "        if len(force_ADC_columns) == 1:\n",
    "            is_non_nan = segmented_force.notna()\n",
    "            group = (is_non_nan != is_non_nan.shift(1)).cumsum()\n",
    "            non_nan_segments = df['F1_ADC'][is_non_nan].groupby(group[is_non_nan])\n",
    "\n",
    "            peak_indices = []\n",
    "            segment_counters = {}\n",
    "            for counter, (group_id, segment) in enumerate(non_nan_segments, 1):\n",
    "                max_idx = segment.idxmax() \n",
    "                if pd.notna(max_idx): \n",
    "                    peak_indices.append(max_idx)\n",
    "                    for idx in segment.index:\n",
    "                        segment_counters[idx] = counter\n",
    "            for idx in peak_indices:\n",
    "                counter = segment_counters[idx]\n",
    "                ax1.axvline(df.loc[idx, 'Timestamp'], linewidth=plot_line_width, linestyle=':', color='gray', alpha=plot_secondary_line_alpha)\n",
    "                ax1.text(df.loc[idx, 'Timestamp'], 400+50*(counter%2), f'{counter}', \n",
    "                        verticalalignment='top', horizontalalignment='center', fontsize=10, color='gray')\n",
    "\n",
    "    # Plots raw data in subplot 2 \n",
    "    for idx, force_ADC_column in enumerate(force_ADC_columns):\n",
    "        line, = ax2.plot(df['Timestamp'], df[force_ADC_column], label=force_ADC_column, color=colors[idx], linewidth=plot_line_width, zorder=10)\n",
    "        lines_ax2.append(line)\n",
    "        ax2.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "        ax2.set_title(f'Raw Forces for {trial_name}', fontsize=plot_title_font_size)\n",
    "\n",
    "    # Plots acceleration and IMU data in subplots 3 and 4 for live fire. \n",
    "    # Todo: This part is incomplete; it plots but does not provide much use. Will be expanded upon once live fire data is available.\n",
    "    if not dry_fire:\n",
    "        for idx, gyro_column in enumerate(gyro_columns):\n",
    "            ax3.grid(which='both')\n",
    "            ax3.yaxis.set_major_locator(MultipleLocator(50))\n",
    "            ax3.yaxis.set_minor_locator(AutoMinorLocator())     \n",
    "            ax3.grid(which='major', axis='y', linestyle='-', color='k', alpha=plot_grid_line_alpha)\n",
    "            ax3.yaxis.set_tick_params(which='major', labelright=True, labelleft=True)\n",
    "            ax3.plot(df['Timestamp'], df[gyro_column], label=gyro_column, color=colors[idx], linewidth=plot_line_width)\n",
    "            ax3.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "\n",
    "        for idx, acc_column in enumerate(acc_columns):\n",
    "            ax4.grid(which='both')\n",
    "            ax4.yaxis.set_major_locator(MultipleLocator(5))\n",
    "            ax4.yaxis.set_minor_locator(AutoMinorLocator())     \n",
    "            ax4.grid(which='major', axis='y', linestyle='-', color='k', alpha=plot_grid_line_alpha)\n",
    "            ax4.yaxis.set_tick_params(which='major', labelright=True, labelleft=True)\n",
    "            ax4.plot(df['Timestamp'], df[acc_column], label=acc_column, color=colors[idx], linewidth=plot_line_width)\n",
    "            ax4.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    for ax in axes:\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90, ha='center')\n",
    "        ax.set_xlabel('Time (HH:MM:SS)')\n",
    "        ax.set_ylabel('Filtered Force (ADC)') if ax is ax1 else ax.set_ylabel('Force (ADC)') if ax is ax2 else ax.set_ylabel('Gyro ()') if ax is ax3 else ax.set_ylabel('Acc ()')\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{trial_name}/{trial_name}.png', dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "    if len(forces_to_plot) == 1:\n",
    "        return peak_indices\n",
    "\n",
    "def check_state(data:pd.Series, threshold:float, previous_state:int) -> int:\n",
    "    \"\"\"\n",
    "    Determines the state of a signal based on its values relative to a threshold.\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): A pandas Series of numeric values to evaluate.\n",
    "        threshold (float): Positive threshold for state comparison.\n",
    "        previous_state (int): Previous state (1, -1, or 0) for hysteresis logic.\n",
    "\n",
    "    Returns:\n",
    "        int: State value (1 if all values >= threshold, -1 if all <= -threshold,\n",
    "            0 if all within [-threshold, threshold], or based on previous_state\n",
    "            for mixed values).\n",
    "    \"\"\"\n",
    "    if (data >= threshold).all():\n",
    "        return 1\n",
    "    if (data <= -threshold).all():\n",
    "        return -1\n",
    "    if (abs(data) < threshold).all():\n",
    "        return 0\n",
    "    return int((data > threshold).any()) if previous_state > 0 else -int((data < -threshold).any()) if previous_state < 0 else 0\n",
    "\n",
    "def peak_event_detection_consecutive(df:pd.DataFrame, threshold_derivative_filter:float, horizon:int, threshold_magnitude:int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detects and segments spike events in a force sensor signal ('F1_ADC') based on a custom\n",
    "    momentum-aware state machine, filtering out non-event spikes based on magnitude.\n",
    "    The function uses the derivative of a rolling average of the force signal to determine\n",
    "    the signal's trend (increase, decrease, or no change). \n",
    "\n",
    "    Parameters:\n",
    "        df : pd.DataFrame\n",
    "            The input DataFrame containing time-series data. It must contain the columns:\n",
    "            'F1_ADC_rolling' (the rolling average of the raw force signal),\n",
    "            'F1_ADC' (the raw force signal), and\n",
    "            'Timestamp' (datetime objects used to calculate the derivative).\n",
    "        threshold_derivative_filter : float\n",
    "            The minimum absolute value of the derivative's moving average required to switch\n",
    "            the trend state from zero (no change) to a positive or negative state.\n",
    "        horizon : int\n",
    "            The horizon length for state evaluation used by the state machine.\n",
    "        threshold_magnitude : int\n",
    "            The minimum peak force value (in 'F1_ADC') a detected spike segment must reach\n",
    "            to be considered a valid event. Segments below this are marked as a secondary\n",
    "            status code (2).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "            The original DataFrame with two new columns added:\n",
    "            'Masks': The internal state (1: increasing trend, -1: decreasing trend, NaN: filtered or neutral).\n",
    "            'Spike_counter': An integer ID (starting from 1) for each detected and kept spike event segment.\n",
    "    \"\"\"\n",
    "\n",
    "    previous_state = 0\n",
    "    masks = pd.Series(0, index=df[f'F1_ADC_rolling'].index)\n",
    "\n",
    "    # Differentiates the moving average of F1\n",
    "    force_rolling_diff = df['F1_ADC_rolling'].diff()\n",
    "    time_diff = df['Timestamp'].diff().dt.total_seconds()\n",
    "    force_rolling_deriv = force_rolling_diff / time_diff\n",
    "\n",
    "    for idx in range (horizon, len(df)+1):\n",
    "        # Checks a unique state that essentuially encapsulates the confidence in the current trend (increase, decrease, or neither) in the signal \n",
    "        # by checking moving_avg(derivative(moving_avg(raw_signal))) and the previous state\n",
    "        current_state = check_state(data=force_rolling_deriv.iloc[idx - horizon: idx], threshold=threshold_derivative_filter, previous_state=previous_state)\n",
    "        if previous_state <= 0:             # Trusts the current state when the previous state does not indicate an increase (decrease or no change)\n",
    "            current_state = current_state\n",
    "        else:                               # Favors the momentum in previous increasing trends, only stopping that momemntum when the current state indicates a decrease\n",
    "            current_state = current_state if current_state < 0 else 1\n",
    "        masks.iloc[idx - horizon] = current_state\n",
    "        previous_state = current_state\n",
    "\n",
    "    group = (masks != masks.shift(1)).cumsum()\n",
    "    segments = masks.groupby(group)\n",
    "    ones_segments = segments.apply(lambda x: x.index if (x == 1).all() else None).dropna()\n",
    "\n",
    "    for segment_indices in ones_segments:\n",
    "        \n",
    "        # Removes spike recorded that are clearly not firearm trigger engagement events due to low peak value \n",
    "        max_f1_adc = df.loc[segment_indices, 'F1_ADC'].max()\n",
    "        if max_f1_adc < threshold_magnitude:\n",
    "            masks.loc[segment_indices] = 2\n",
    "            \n",
    "            last_idx = segment_indices[-1]\n",
    "            pos = masks.index.get_loc(last_idx)\n",
    "            if pos < len(masks) - 1:\n",
    "                next_pos = pos + 1\n",
    "                next_indices = []\n",
    "                while next_pos < len(masks) and masks.iloc[next_pos] == -1:\n",
    "                    next_indices.append(masks.index[next_pos])\n",
    "                    next_pos += 1\n",
    "                if next_indices:\n",
    "                    masks.loc[next_indices] = 2\n",
    "\n",
    "    # Keeping and extarcing relevant segments and numbering them\n",
    "    df['Masks'] = masks.where(masks.isin([1, -1]), np.nan)\n",
    "    is_non_nan = df['Masks'].notna()                                       \n",
    "    group_ids = (is_non_nan != is_non_nan.shift()).cumsum()              \n",
    "    non_nan_groups = group_ids[is_non_nan]                                \n",
    "    segment_numbers = non_nan_groups.groupby(non_nan_groups).ngroup() + 1  \n",
    "\n",
    "    full_segment_series = pd.Series(segment_numbers, index=non_nan_groups.index)\n",
    "    df['Spike_counter'] = full_segment_series \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sorted_keys = sorted(data_dict.keys(), key=extract_key_components)      \n",
    "    data_dict = {key: data_dict[key] for key in sorted_keys}\n",
    "\n",
    "    for key, value in data_dict.items():\n",
    "        base_name, task = get_trial_name(key)\n",
    "        company_id, user_id = extract_key_components(key)\n",
    "        is_trial_data = True if task.startswith('U') else False     # Only run the segmentor on the sensor data\n",
    "\n",
    "        if is_trial_data:\n",
    "            data_df = value.copy()\n",
    "            data_df['Timestamp'] = data_df['Timestamp'].str.replace(r'(\\d{2}:\\d{2}:\\d{2}):(\\d{3}Z)', r'\\1.\\2', regex=True)\n",
    "            data_df['Timestamp'] = pd.to_datetime(data_df['Timestamp'])\n",
    "\n",
    "            # Segmentation\n",
    "            calibration_df = calibration_dict[key.strip(f'{'_U'}') + '_Trial'].copy()\n",
    "            data_df[f'F1_ADC_rolling'] = data_df[f'F1_ADC'].rolling(window=rolling_window_width, center=True, min_periods=1).mean()     # Todo: Currently hard-coded to channel 1 for dry fire, not sure if changes will be needed\n",
    "            filtered_df = peak_event_detection_consecutive(df=data_df, threshold_derivative_filter=event_derivative_threshold_ADC, horizon=horizon, threshold_magnitude=magnitude_threshold_ADC)\n",
    "        \n",
    "            os.makedirs(base_name, exist_ok=True)\n",
    "            peak_indices = plot_trial(base_name, filtered_df, dry_fire=dry_fire, start=plot_start_time, end=plot_end_time)\n",
    "            filtered_df.to_csv(f'{base_name}/{base_name}_filtered.csv', index=False)\n",
    "\n",
    "            # Segmentation for annontation\n",
    "            if len(forces_to_plot) == 1 and not os.path.isfile(f'{base_name}/{base_name}_annotation.csv'):\n",
    "                segmentation_df_csv = pd.DataFrame({\n",
    "                    'Company': company_id,\n",
    "                    'User': user_id,\n",
    "                    'Time': data_df.loc[peak_indices, 'Timestamp'],\n",
    "                    'Counter': range(1, len(peak_indices) + 1),\n",
    "                    'Keep': np.nan,\n",
    "                    'Trigger': np.nan,\n",
    "                    'Grip': np.nan\n",
    "                })\n",
    "\n",
    "                segmentation_df_csv.to_csv(f'{base_name}/{base_name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
